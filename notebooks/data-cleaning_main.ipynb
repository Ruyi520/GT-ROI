{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "* Head orientation coordinate matching in CSV file\n",
    "* Image sourcing, resize and match with allocated timestamped label\n",
    "* Eye coordinates using an iris detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4395, 4)\n",
      "(2722, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, os.path\n",
    "import cv2\n",
    "import import_ipynb\n",
    "#from attentiondetector import *\n",
    "\n",
    "#We read our labels from two cvs files and do some conversions. The video frames \n",
    "#are read from our directory into our data genrators. We create our dataframe and \n",
    "#add our columned-labels from a pretrained classifier to create our head orientation labels\n",
    "\n",
    "#We curate our labels from two cvs files of shape(4395, 4) and (2722, 4) respectively.\n",
    "data_path01 = \"../data/unclean_label/clean_label/clean_label01.csv\"\n",
    "data_path02 = \"../data/unclean_label/clean_label/clean_label02.csv\"\n",
    "unclean_label = \"../data/unclean_label/unclean_label.csv\"\n",
    "\n",
    "def convert_dtype(path):\n",
    "    data = pd.read_csv(path)\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.iloc[:,4:8]\n",
    "    df = df.dropna(axis=0,how='any')\n",
    "    df = np.array(df,dtype='int64')\n",
    "    for i in df:\n",
    "        for j in i:\n",
    "            j = j.astype('int')\n",
    "    return df\n",
    "df1 = convert_dtype(data_path01)\n",
    "df2 = convert_dtype(data_path02)\n",
    "\n",
    "print(df1.shape)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1582947215462             0             0             0]\n",
      " [1582947215465             0             0             0]\n",
      " [1582947215469             0             0             0]\n",
      " ...\n",
      " [1583028965938           -20             7           -56]\n",
      " [1583028965949           -20             7           -56]\n",
      " [1583028965959           -20             7           -56]]\n"
     ]
    }
   ],
   "source": [
    "df = np.concatenate([df1,df2])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6885\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "#We convert our labels to a dictionary with the timestamp as keys and PRY as values\n",
    "\n",
    "Dict = OrderedDict()\n",
    "for i in df:\n",
    "    timestamp = int((i[0])/10)\n",
    "    Dict[timestamp] = [i[1],i[2],i[3]]\n",
    "\n",
    "print(len(Dict.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is number:1 video\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-071af7025910>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mvideopath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This is number:{} video\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mtimestamp_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_timestamps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideopath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mdata_TS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestamp_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mcount1\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-071af7025910>\u001b[0m in \u001b[0;36mget_timestamps\u001b[0;34m(vid_path, start_time)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/tf_data/{}.jpg'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mFTS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_PROP_POS_MSEC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFTS\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os,os.path\n",
    "import numpy as np\n",
    "\n",
    "v_path = \"../data/unclean_data/clean\"\n",
    "\n",
    "#An arrary of timestamps of the first frame of each video is recorded for calculating all frames timestamp\n",
    "TS = [158294721650,158302893900]\n",
    "\n",
    "#This function takes a video path and returns an array of timestamp of len(vid_path)\n",
    "def get_timestamps(vid_path,start_time):\n",
    "    video = cv2.VideoCapture(vid_path)\n",
    "    FC = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    timestamps = []\n",
    "    count = 0\n",
    "    while video.isOpened():\n",
    "        ret,frame = video.read()\n",
    "        frame = np.array(frame)\n",
    "        #cv2.imwrite('../data/tf_data/{}.jpg'.format(count), frame)\n",
    "        FTS = video.get(cv2.CAP_PROP_POS_MSEC)\n",
    "        timestamp = int(start_time + FTS/10)\n",
    "        timestamps.append(timestamp)\n",
    "        count+=1\n",
    "        if count== FC: break\n",
    "    return timestamps\n",
    "\n",
    "data_TS = []\n",
    "\n",
    "#We call our get_timestamps function on each video in our cwd\n",
    "count1 = 0\n",
    "for j in os.listdir(v_path):\n",
    "    if j.endswith(\".mp4\"):\n",
    "        videopath = os.path.join(v_path,j)\n",
    "        print(\"This is number:{} video\".format(count1+1))\n",
    "        timestamp_arr = get_timestamps(videopath,TS[count1])\n",
    "        data_TS.extend(timestamp_arr)\n",
    "        count1+=1                                                                             \n",
    "    else:\n",
    "        continue\n",
    "\n",
    "\n",
    "data_TS = np.array(data_TS).flatten()\n",
    "print(len(data_TS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "#Here, we match the timestamps of our frames to it's respective PRY(pitch, roll yaw) value\n",
    "\n",
    "print(len(data_TS))\n",
    "print(len(Dict))\n",
    "\n",
    "def get_est(Dict,x):\n",
    "    for i,j in enumerate(Dict.keys()):\n",
    "        if j==x:\n",
    "            break\n",
    "        elif j<x:\n",
    "            continue\n",
    "        else:\n",
    "            break  \n",
    "    return j\n",
    "\n",
    "_match = OrderedDict()\n",
    "\n",
    "for j in data_TS:\n",
    "    if j in Dict.keys():\n",
    "        _match[j] = Dict[j]\n",
    "    else:\n",
    "        est = get_est(Dict,j)\n",
    "        _match[j] = Dict[est]\n",
    "        continue\n",
    "        \n",
    "print(len(_match))\n",
    "\n",
    "with open('../data/tf_label/labels.csv','w') as w:\n",
    "    writer = csv.writer(w)\n",
    "    writer.writerows(_match.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
