{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaze vector estimation and visualization\n",
    "\n",
    "This notebook is a reference to _Paper: gaze estimation using a camera-based model in a classroom_ for running preliminary analysis on a webcam.\n",
    "To run this notebook, a built-in webcam and good lighting is required. Meanwhile, some operating systems may require additional firewall settings to gain camera access. We make use of opencv's library to perform video processing and analysis for prelimninary tests on gaze capture.\n",
    "\n",
    "Our gaze estimation application can be sectioned into:\n",
    " - Data pre-processing (face and eye detection)\n",
    " - Head pose classifiers (Euler angles: ùõº,ùúÉ,ùúî) or reference plane\n",
    " - Attention boundary/matrix\n",
    " - Depth estimation function\n",
    " - Composition and visualization of gaze vector frequencies\n",
    "Here, our model is primarily based on the relibility of our pre-trained face/eye detection(haarcascades). This dependency may undermine overall perfomance at scale. We aim to detect and identify multiple candidates in each frame of the image in order to estimate head and iris orientation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display video files\n",
    "A sample video input stream for opening video files and obtaining frame properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import cv2\n",
    "import os\n",
    "\n",
    "videopath = '../data/glasses.mp4'\n",
    "video = cv2.VideoCapture(videopath)\n",
    "while video.isOpened():\n",
    "    ret, frame = video.read()\n",
    "    cv2.imshow('frame', frame)\n",
    "    \"\"\"fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    width = video.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    height = video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    timestamp = video.get(cv2.CAP_PROP_POS_MSEC)\"\"\"\n",
    "    if cv2.waitKey(25)== ord('q'):\n",
    "        video.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face and eye detection\n",
    "We detect each faces per frame using the _frontal view haarcascade classifier_. Gaze vector is a function of the eye coordinates relative to its' reference plane **RP** (which is addressed in Section 2). Afterwards, the face frame object is passed to the eye classifier. In the following two cells, we extract faces and iris coordinates shown in bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Neo/Documents/Documents - lars‚Äôs MacBook Pro/Thesis Project/notebooks\n"
     ]
    }
   ],
   "source": [
    "#We create our library dependecies and global variables for our little test algorithm for a face and eye tracker\n",
    "import cv2, time, os\n",
    "import PIL.Image\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import dlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(os.getcwd())\n",
    "path01 = '../data/haarcascades'\n",
    "path02 = \"../iris-tracker-by-contours/shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "#We create our pre-trained cascade objects for face and eye\n",
    "f = \"haarcascade_frontalface_default.xml\"\n",
    "e = \"haarcascade_eye.xml\"\n",
    "le = \"haarcascade_lefteye_2splits\"\n",
    "re = \"haarcascade_righteye_2splits\"\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(os.path.join(path,f))\n",
    "eye_cascade = cv2.CascadeClassifier(os.path.join(path,e))\n",
    "le_cascade = cv2.CascadeClassifier(os.path.join(path,le))\n",
    "re_cascade = cv2.CascadeClassifier(os.path.join(path,re))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import numpy.linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'face_utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-29bc940b02ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../iris-tracker-by-contours/shape_predictor_68_face_landmarks.dat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mlStart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlEnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFACIAL_LANDMARKS_IDXS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"left_eye\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mrStart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrEnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFACIAL_LANDMARKS_IDXS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"right_eye\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'face_utils' is not defined"
     ]
    }
   ],
   "source": [
    "vs = cv2.VideoCapture(0)\n",
    "numerator=0\n",
    "denominator=0\n",
    "\n",
    "#Instantiate frontal face detector\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"../iris-tracker-by-contours/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "lStart, lEnd = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "rStart, rEnd = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "\n",
    "#We define a fun eye aspect ratio function EAR()\n",
    "def EAR(eye):\n",
    "    # compute the euclidean distances between the two sets of\n",
    "    # vertical eye landmarks (x, y)-coordinates\n",
    "    A = np.linalg.norm(eye[1] - eye[5])\n",
    "    B = np.linalg.norm(eye[2] - eye[4])\n",
    "\n",
    "    # compute the euclidean distance between the horizontal\n",
    "    # eye landmark (x, y)-coordinates\n",
    "    C = np.linalg.norm(eye[0] - eye[3])\n",
    "\n",
    "    # compute the eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "\n",
    "    # return the eye aspect ratio\n",
    "    return ear\n",
    "\n",
    "while True:\n",
    "    _,frame = vs.read()\n",
    "    roi = frame\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # detect dlib face rectangles\n",
    "    faces = detector(gray, 0)\n",
    "\n",
    "    for face in faces:\n",
    "        eyes = []\n",
    "        \n",
    "        # convert dlib rect to a bounding box\n",
    "        (x,y,w,h) = face_utils.rect_to_bb(face)\n",
    "        \n",
    "        # print(x,y,w,h)\n",
    "        xc,yc = (x+w/2,y+h/2)\n",
    "        radius = (w**2+h**2)**0.5\n",
    "        \n",
    "        #cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),1)\n",
    "        cv2.circle(frame,(xc,yc), radius, (255,0,0), thickness=1)\n",
    "\n",
    "        # get the landmarks from dlib, convert to np array\n",
    "        shape = predictor(gray, face)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        \n",
    "        # indexes for left and right eye key points\n",
    "        leftEye = shape[lStart:lEnd]  \n",
    "        rightEye = shape[rStart:rEnd]\n",
    "\n",
    "        eyes.append(leftEye)  #wrap in a list\n",
    "        eyes.append(rightEye)\n",
    "        \n",
    "        # save the state of both eyes to print\n",
    "        both_eyes_state = []\n",
    "\n",
    "        # loop through both eyes\n",
    "        for index, eye in enumerate(eyes):\n",
    "\n",
    "            eye_EAR = eye_aspect_ratio(eye)\n",
    "\n",
    "            single_eye_state = []  # first entry is eye index, second entry is the closed or eye direction state\n",
    "\n",
    "            left_side_eye = eye[0]  # left edge of eye\n",
    "            right_side_eye = eye[3]  # right edge of eye\n",
    "            top_side_eye = eye[1]  # top side of eye\n",
    "            bottom_side_eye = eye[4]  # bottom side of eye\n",
    "\n",
    "            # calculate height and width of dlib eye keypoints\n",
    "            eye_width = right_side_eye[0] - left_side_eye[0]\n",
    "            eye_height = bottom_side_eye[1] - top_side_eye[1]\n",
    "\n",
    "            # create bounding box with buffer around keypoints\n",
    "            eye_x1 = int(left_side_eye[0] - 0 * eye_width)  # .25 works well too\n",
    "            eye_x2 = int(right_side_eye[0] + 0 * eye_height)  # .75 works well too\n",
    "\n",
    "            eye_y1 = int(top_side_eye[1] - 1 * eye_height)\n",
    "            eye_y2 = int(bottom_side_eye[1] + 1 * eye_height)\n",
    "\n",
    "            # draw bounding box around eye roi\n",
    "            cv2.rectangle(frame,(eye_x1, eye_y1), (eye_x2, eye_y2),(0,255,0),2)\n",
    "\n",
    "            # draw the circles for the eye landmarks\n",
    "            for i in eye:\n",
    "                cv2.circle(frame, tuple(i), 3, (0, 0, 255), -1)\n",
    "\n",
    "        #------------ estimation of distance of the human from camera--------------#\n",
    "            # d=10920.0/float(w)\n",
    "\n",
    "            roi = frame[eye_y1:eye_y2,eye_x1:eye_x2]\n",
    "\n",
    "            #  ---------    check if eyes open   -------------  #\n",
    "\n",
    "            # state is open/close, or direction looking\n",
    "            eye_state = None\n",
    "\n",
    "            if eye_EAR > 0.25:\n",
    "\n",
    "                #  ---------    find center of pupil   -------------  #\n",
    "\n",
    "                gray=cv2.cvtColor(roi,cv2.COLOR_BGR2GRAY)  # grey scale convert\n",
    "                blur = cv2.medianBlur(gray,5) # blue image to find the iris better\n",
    "                equ = cv2.equalizeHist(blur)  # ie, improve contrast by spreading the range over the same window of intensity\n",
    "                thres=cv2.inRange(equ,0,15)  # threshold the contour edges, higher number means more will be black\n",
    "                kernel = np.ones((3,3),np.uint8)  # placeholder\n",
    "\n",
    "            #     #/------- removing small noise inside the white image ---------/#\n",
    "                dilation = cv2.dilate(thres,kernel,iterations = 2)\n",
    "            #     #/------- decreasing the size of the white region -------------/#\n",
    "                erosion = cv2.erode(dilation,kernel,iterations = 3)\n",
    "            #     #/-------- finding the contours -------------------------------/#\n",
    "                image, contours, hierarchy = cv2.findContours(erosion,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "            #     #--------- checking for 2 contours found or not ----------------#\n",
    "\n",
    "                pupil_found = None\n",
    "\n",
    "                if len(contours)==2 :\n",
    "                    # print('2 contours found')\n",
    "                    pupil_found = True\n",
    "\n",
    "                    img = cv2.drawContours(roi, contours, 1, (0,255,0), 3)\n",
    "                    #------ finding the centroid of the contour ----------------#\n",
    "                    M = cv2.moments(contours[1])\n",
    "\n",
    "                    if M['m00']!=0:\n",
    "                        cx = int(M['m10']/M['m00'])\n",
    "                        cy = int(M['m01']/M['m00'])\n",
    "                        cv2.line(roi,(cx,cy),(cx,cy),(0,0,255),3)\n",
    "                        # print(cx,cy)\n",
    "                #-------- checking for one contour present --------------------#\n",
    "\n",
    "                if len(contours)==1:\n",
    "                    pupil_found = True\n",
    "                    # print('only 1 contour found ------- ')\n",
    "\n",
    "                    img = cv2.drawContours(roi, contours, 0, (0,255,0), 3)\n",
    "\n",
    "                    #------- finding centroid of the contour ----#\n",
    "                    M = cv2.moments(contours[0])\n",
    "                    if M['m00']!=0:\n",
    "                        cx = int(M['m10']/M['m00'])\n",
    "                        cy = int(M['m01']/M['m00'])\n",
    "                        # print(cx,cy)\n",
    "                        cv2.line(roi,(cx,cy),(cx,cy),(0,0,255),3)\n",
    "\n",
    "                if pupil_found:\n",
    "                    # find ratio of distance from each side of the eye bounding box\n",
    "                    # to get quantify direction of pupil\n",
    "\n",
    "                    width_ratio = cx / eye_width\n",
    "                    height_ratio = cy / (eye_y2 - eye_y1)  # make sure to use bounding box height\n",
    "\n",
    "                    if (width_ratio < 0.4):\n",
    "                        print('Looking right')\n",
    "                        single_eye_state.append(index)\n",
    "                        single_eye_state.append('Right')\n",
    "                    elif (width_ratio > 0.6):\n",
    "                        print('Looking left')\n",
    "                        single_eye_state.append(index)\n",
    "                        single_eye_state.append('Left')\n",
    "                    elif (height_ratio < 0.35):\n",
    "                        print('Looking up')\n",
    "                        single_eye_state.append(index)\n",
    "                        single_eye_state.append('Up')\n",
    "                    else:\n",
    "                        print('Looking forward')\n",
    "                        single_eye_state.append(index)\n",
    "                        single_eye_state.append('Forward')\n",
    "\n",
    "                # eyes are opened, but pupils not found\n",
    "                else:\n",
    "                    print('Pupil not found')\n",
    "                    single_eye_state.append(index)\n",
    "                    single_eye_state.append('No pupil found')\n",
    "\n",
    "                # doens't really work because it appears eyes are closed when\n",
    "                # looking down\n",
    "                # if (height_ratio > 0.50):\n",
    "                #     print('Looking down')\n",
    "\n",
    "            # if height / width < 0.3, then eye is closed, or person is looking down\n",
    "            else:\n",
    "                single_eye_state.append(index)\n",
    "                single_eye_state.append('Closed')\n",
    "\n",
    "            # end loop for one eye\n",
    "            both_eyes_state.append(single_eye_state)\n",
    "\n",
    "        # end loop for one face\n",
    "        # write state for both eyes\n",
    "\n",
    "        for ind, eye in enumerate(both_eyes_state):\n",
    "            # print(eye)\n",
    "            eye_num = ['Left', 'Right']\n",
    "            # text = 'Hello'\n",
    "            text = '{} eye is looking:  {}'.format(eye_num[ind], eye[1])\n",
    "\n",
    "            cv2.putText(frame, text, (50, 50*(ind+1)), \\\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "vs.release()\n",
    "# print(\"accurracy=\",(float(numerator)/float(numerator+denominator))*100)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create our eye class which contain our eye coordinates\n",
    "class Eye():\n",
    "    def __init__(self,x, y, x2, y2):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.x2 = x2\n",
    "        self.y2 = y2\n",
    "        self.width = x2 - x\n",
    "        self.height = y2 - y\n",
    "        self.topcorner = (x, y)\n",
    "        self.bottomcorner = (x2, y2)\n",
    "\n",
    "def detect_eyes(image, classifierObject_e):\n",
    "    eyes = classifierObject_e.detectMultiScale(image)\n",
    "    right_eye = None\n",
    "    left_eye = None\n",
    "    \n",
    "    if eyes is not None:\n",
    "        for eye in eyes:\n",
    "            x, y = (eye[0], eye[1])\n",
    "            x2, y2 = (eye[0]+eye[2], eye[1] + eye[3])\n",
    "            \n",
    "            if right_eye is None:\n",
    "                right_eye = Eye(x,y,x2,y2)\n",
    "                continue\n",
    "            else:\n",
    "                left_eye = Eye(x,y,x2,y2)\n",
    "                break\n",
    "    return right_eye, left_eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unexpected version found while deserializing dlib::shape_predictor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-479c562f7c56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/shape_predictor_68_face_landmarks.dat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m#Returns a 1 X 4 array with bounding box coordinates(x, y , w, h) of detected faces of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unexpected version found while deserializing dlib::shape_predictor."
     ]
    }
   ],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame,1)\n",
    "\n",
    "    #We read each image from the stream and convert to gray scale \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #I used these to tune the input image over intensity thresholds with some built-in cv2 functions\n",
    "    \"\"\"\n",
    "    edged = cv2.Canny(gray, 30, 200)\n",
    "    thresh = cv2.threshold(blurred,60, 255, cv2.THRESH_BINARY)[1]\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    dilate = cv2.dilate(thresh.copy(), kernel, iterations = 2)\n",
    "    \"\"\"\n",
    "\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"../data/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    #Returns a 1 X 4 array with bounding box coordinates(x, y , w, h) of detected faces of \n",
    "    #the image with scale factor\n",
    "    faces = face_cascade.detectMultiScale(gray,1.5, 5)\n",
    "    if faces is not None:\n",
    "        for face in faces:\n",
    "            x,y,w,h = face\n",
    "\n",
    "            #Draw a rectantle around the face\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,0),3)\n",
    "\n",
    "            #Extract image of face\n",
    "            face_frame = frame[x:x+w,y:y+h]\n",
    "\n",
    "            #Detect eyes each face_frame\n",
    "            eyes = detect_eyes(frame, eye_cascade)\n",
    "\n",
    "            if eyes is not None:\n",
    "                try:\n",
    "                    cv2.rectangle(frame, eyes[0].topcorner, eyes[0].bottomcorner, (0,0,255),3)\n",
    "                    cv2.rectangle(frame, eyes[1].topcorner, eyes[1].bottomcorner, (0,255,0),3)\n",
    "                except AttributeError:\n",
    "                    continue\n",
    "            continue\n",
    "\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "         break\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Head pose classifiers (Euler angles: ùõº,ùúÉ,ùúî) or reference plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import boto3\n",
    "#boto3.client('rekognition')\n",
    "#boto3.client('kinesisvideo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-18395105c7f1>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-18395105c7f1>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    model.add(Convo2D(0.5*len(height)),(3,3))\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Create our head orientation estimator which comprises of three mini-classifiers (ùõº,ùúÉ,ùúî)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models.layers import Dense, Dropout, Activation, Flatten, Convo2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "import pickle\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convo2D(image_shape, filters = ,kernel = (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2))\n",
    "\n",
    "model.add(Convo2D(0.5*len(height)),(3,3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Maxpooling2D(pool_size=(2,2)))\n",
    "          \n",
    "model.add(Flatten())\n",
    "model.add(Dense(32))\n",
    "          \n",
    "model.add(Dense(4))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "          \n",
    "model.compile(loss = \"binary_crossentropy\", \n",
    "              optimizer =\"adam\", \n",
    "              metrics =['accuracy'])\n",
    "model.fit(x,y,bath_size = 32 ,validation_split =0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pynput'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-07b9b95d497f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Annotation module for extracting on-screen cursor coordinates for classifier labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpynput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpynput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmouse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mButton\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mController\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmouse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mController\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pynput'"
     ]
    }
   ],
   "source": [
    "#Annotation module for extracting on-screen cursor coordinates for classifier labels\n",
    "\n",
    "import pynput\n",
    "from pynput.mouse import Button, Controller\n",
    "mouse = Controller()\n",
    "mouse.position = (10,20)\n",
    "mouse.move(100,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6*x\n",
      "12.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x121db9978>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sympy as sp\n",
    "x = sp.Symbol('x')\n",
    "print(sp.diff(3*x**2 + 1,x))\n",
    "\n",
    "from scipy.misc import derivative\n",
    "def f(x):\n",
    "    return 3*x**2 + 1\n",
    "print(derivative(f,2.0))\n",
    "\n",
    "def d(x):\n",
    "    return derivative(f,x)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "y = np.linspace(-3,3)\n",
    "plt.plot(y,f(y))\n",
    "plt.plot(y,d(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function get_frontal_face_detector in module dlib:\n",
      "\n",
      "get_frontal_face_detector(...) method of builtins.PyCapsule instance\n",
      "    get_frontal_face_detector() -> dlib::object_detector<dlib::scan_fhog_pyramid<dlib::pyramid_down<6u>, dlib::default_fhog_feature_extractor> >\n",
      "    \n",
      "    Returns the default face detector\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import dlib\n",
    "help(dlib.get_frontal_face_detector)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                             "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
